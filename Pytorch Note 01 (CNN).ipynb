{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Note 01 (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset\n",
    "2. DataLoader\n",
    "3. Declaration of Model\n",
    "4. Initialization Before Training\n",
    "5. Training\n",
    "6. Important Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename, mode):\n",
    "    x = []\n",
    "    y = []\n",
    "    f = open(filename, 'r')\n",
    "    row = csv.reader(f, delimiter=' ')\n",
    "    n_row = 0\n",
    "    for r in row:\n",
    "        if n_row != 0:\n",
    "            temp = []\n",
    "            for i in range(len(r)):\n",
    "                if i == 0:\n",
    "                    if mode == 'train': \n",
    "                        y.append(int(r[0][0]))\n",
    "                        temp.append(int(r[0][2:]))\n",
    "                    else:\n",
    "                        temp.append(int(r[0][len(str(n_row)) + 1:]))\n",
    "                else:\n",
    "                    temp.append(int(r[i]))\n",
    "            x.append(temp)\n",
    "        n_row += 1\n",
    "    f.close()\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x = x.reshape(x.shape[0], 1, 48, 48)\n",
    "    x = x / 255\n",
    "\n",
    "    if mode == 'train': return x, y\n",
    "    else: return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, filename, train, transform=None):\n",
    "        self.x, self.y = loadData(filename, train)\n",
    "        self.x = self.x.astype(np.float32)                               #[1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\__init__(self, ...): Get data and initialize the attributes of Dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\__getitem__(self, index): Do the transforms and return x, y with index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\__len__(self): Return the number of datas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "data = Data('train.csv', 'True', ToTensor())\n",
    "train_loader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 60, 5)\n",
    "        self.conv2 = nn.Conv2d(60, 120, 3)\n",
    "        self.conv3 = nn.Conv2d(120, 240, 3)\n",
    "\n",
    "        self.l1 = nn.Linear(4*4*240, 400)\n",
    "        self.out = nn.Linear(400, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.l1(x))\n",
    "        output = self.out(x)                                              #[2]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\__init__(self): Declarations of the layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward(self, x): How the variable go through the model, and return the output (the prediction of the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = CNN().float()                                                     #[1]\n",
    "model.cuda() #Move the model to gpu.\n",
    "\n",
    "optim = Adam(model.parameters(), lr=LR) #Declaration of optimizer.\n",
    "loss_function = nn.CrossEntropyLoss() #Declaration of loss_function.      #[2]\n",
    "loss_function.cuda() #Move the loss_function to gpu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for iter, (x, y) in enumerate(train_loader):                          #[3]\n",
    "        #Only Variable can compute gradients in Pytorch 0.3.0.\n",
    "        #Move the datas to gpu.\n",
    "        x = Variable(x.cuda())\n",
    "        y = Variable(y.cuda()).long()                                     #[4]\n",
    "        \n",
    "        optim.zero_grad() #Clear the gradients of the optimizer\n",
    "        output = model(x) #Get the prediction of the model\n",
    "        loss = loss_function(output, y) #Get the loss\n",
    "        loss.backward() #Get the gradients\n",
    "        optim.step() #Update the weights in the optimizer\n",
    "        \n",
    "        if (iter + 1) % 5 == 0:\n",
    "            print('Epoch:', epoch + 1, '| Iter:', iter + 1, '| train loss:%.4f' %loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] If the datas are DoubleTensor, executing time would increase explosively in \"x = Variable(x.cuda())\". Therefore the datas were suggested to be transform into float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] torch.nn.CrossEntropyLoss does softmax automatically, so there's no need to do softmax in the last layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] While getting datas in DataLoader, it would call \\__getitem__ in Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] The target of torch.nn.CrossEntropyLoss() must be int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
